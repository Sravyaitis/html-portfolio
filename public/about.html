<h1>About Me</h1>
<p>12 years of Professional Experience in which 3 years of experience as a Python Developer in cloud migration projects migrating to Google Cloud Platform and 9 years’ experience as automation test engineer/ETL Analyst/SDET/Web Application Tester/QA Engineer in various domains. Good at OOPS concepts and design patterns.</p>

<p>Work Experience


 
  Team:  GDIA 									                   
  ·	As part of Product Engineering and Management (PEM) is Global Data Insight and Analytics (GDIA)’s primary responsibilities include:
  ·	Collaborated directly and continuously with business partners, product managers and designers in the development of Python based applications.
  ·	Worked hands-on with the team and other stakeholders to deliver quality software products that meet our customer’s requirements and needs.  
  ·	Help business partners understand our iterative development approach and focus on delivering a Minimum Viable Product (MVP) through careful and deliberate prioritization.
  ·	Grow technical capabilities / expertise and provide guidance to other members on the team.
  ·	Worked on Angular UI project for developing features as per product designer and data scientists. Worked closely with data scientists to gather the requirements.
  ·	Successfully migrated the backend project in microservices and Angular UI from PCF to GCP. Migrated the database from SQL Server to PostgreSQL hosted in GCP.
  ·	Validated the backend API’s using postman. Authenticated the API’s using Azure JWT validations. Published the API’s in API catalogue.
  ·	Created dev, qa, production pipeline configurations files and configured them to run tekton builds and create an instance in gcp. Mapped these instances in respective backend microservices properties file and UI environment files.
  ·	Upgraded Angular UI project from Angular 10 to Angular 15. Fixed the broken UI when upgrading each version at a time.
  ·	Migrated backend Microservices project from Springfox to Springdocs. Worked on Sonarqube and other security tools like checkmarx to reach the maximum test coverage.
  ·	Generated swagger document to test API’s used in the backend microservices using 42 crunch application. Upgraded springboot framework from older versions to newer.
  ·	Participated in iteration planning meetings, retrospective meetings, tech meetings, design change meetings and daily standups. Worked with Architects to get necessary approvals and lay an architecture for the project. 
  ·	Integrated UI with backend microservices after migrating the applications to cloudrun GCP.
  ·	Added secrets to secret manager. Checked code in github. Experience using Jira, Confluence, Google Workspace, and Slack.
  
  Team: Interfaces   
  ·	Developed modern, efficient, and robust backend applications, APIs, and data-design in a cloud environment using Python.
  ·	Excellent troubleshooting skills, when it comes to discovering the root of the problem, identifying potential solutions, and implementing an approach to avoid repeat of the issue.
  ·	Wrote production-quality software in Python that is understandable, testable, and has an eye toward maintainability.
  ·	Integrated frontend and backend systems via HTTP APIs, including rapid consumption of REST-based web services using JSON with client-side technologies such as HTML5, CSS3, and React.
  ·	Implemented best practices and automation to improve the stakeholder experience when using Cloud platforms and services for application development.
  ·	Accelerated client onboarding with feature development on cloud platforms and services through education, architectural consultations, and guidance, along with owning and building strategic tools to enable application teams to transition and utilize cloud platforms effectively.
  ·	Worked closely with the development teams, data analytics, business analysts and stakeholders for new feature development. Have built docker images and containers. Build and operate container-based (e.g. Kubernetes) solutions.
  ·	Authored serverless code in python for GCP. Good understanding of Python and its libraries/frameworks (e.g., Django, Flask).
  
  Team: Interfaces
  ·	Tested web-based applications and websites, including UI testing and cross-browser compatibility testing in React-based applications.
  ·	Tested REST APIs, GraphQL, and WebSocket. Worked on load testing tools, such as JMeter.
  ·	Wrote and implement detailed test cases, test plans, and test design documents.
  ·	Git branching, tagging, and code deployment best practices. Experience in architecting and building/customizing a test framework from scratch.
  ·	Understanding of Typescript/Javascript and dynamic frontend fundamentals.
  ·	Strong knowledge of API testing techniques and tools, such as Postman or similar tools.
  ·	Collaborated with software developers to create integration tests for new features.
  ·	Performed software demos at end of sprints. Participated in regular Scrum events such as sprint planning, review, and retrospective. Have setup automated software development pipelines for continuous and regression test activities.
  
     Project: Smart Grid Analytics and Outage Management System
  ·	Created and Executed Smoke, System, Functional and Regression test cases in ALM. Mapped the requirement to test cases in ALM.
  ·	Ran Pig scripts in Free Windows Explorer based GUI file manager- Hadoop Distributed File System (HDFS) to move data from Common Data Landing Zone to Hive Stage Database.
  ·	Used HPQC 11 for logging defects. Database testing using SQL queries for data verification in backend tables. Documented the traceability of scripts to requirements in ALM.
  
     Project: Address and Account Maintenance projects for SmartWorks Application
  ·	Ran Automation scripts using Cucumber which maintains official Gherkin language standard. Involved in Framework Design. Wrote Behavior driven scenarios (BDD) with “.feature” files extension.
  ·	Wrote automation scenarios for the behavior under test.
  ·	Used Log4J for Logging. Worked on Maven for application building, scheduling, and automation.
  ·	Tested Brokerage processing through third party application Broadridge Processing System, most trusted transaction-processing platform for many investments.
  ·	Worked on automating the applications that reduced the involvement of Back Office Users and many Reps. Experience on Data validation, Data merging, Data cleansing and Data aggregation activities.
  ·	Validated the data against staging tables and warehouse.
  ·	Involved in understanding the Requirements of the end Users/Business Analysts and Developed Strategies for ETL processes. 
  ·	Analyzed the business requirements and Functional Specs for developing Test Plan and the Test Strategy.
  
     Project: Market Data testing of the Trading application in CME group
  ·	Knowledge in FIX message protocol and architecture, have worked in FIX message validations and book management.
  ·	Analysis of Business requirements, test scenario authoring, test case creation in ATE tool – Cucumber and CME tool – Brio. Executed test scripts in Eclipse (IDE).
  ·	UNIX box navigation and Log validations– VI editor /Shell scripting.
  ·	Performed Unit, functional, integration, regression, UAT, Performance and end to end testing for this project. Extensively used Oracle/Teradata to write SQL Queries to verify and validate the Database Updates.
  
     Project: Multiple Loan and Credit card service projects. 
  ·	Analysis of Business requirements & Design Specification Document to determine the functionality of the ETL Processes. Experience in testing web services using SOAP UI.
  ·	Experience in Browser Compliance test case development and execution.
  ·	Created test plan and test cases from the business requirements to match the project’s initiatives in Quality Center. Used SQL for Querying the UDB DB2 database in UNIX environment. 
  ·	Verified the data in DW tables after extracting the data from source tables by writing SQL queries using TOAD. Involved in Database tuning to enhance the application performance.
  
     Projects: Inventory Visibility, Transfers, Supply Chain Visibility, Customer Order Management
  ·	Experience on Data validation, Data merging, Data cleansing and Data aggregation activities.
  ·	Responsible for ETL batch jobs execution using IBM Tivoli application to load data from core database (i.e. ETM database) to Staging and Data mart tables.
  ·	Perform Sanity Testing, Data Driven Testing & Ad-hoc Testing when required.
  ·	Performed Interface and Integration (SIT) Testing.
  ·	Extensively used SQL queries for data validation and backend testing.
  ·	Working with Data base testing Involved in Data Migration Testing and preparing documents. Functionality, Interface, and Regression testing.
  ·	Track Sheet Maintenance and map the use case to requirement. Monitor Testing Activities within the team and report regular progress to the Test Manager.
  ·	Working with Tivoli job scheduler for submitting the jobs and monitoring the jobs.
  ·	Worked with job scheduler tool Tivoli for running the ETL batch jobs and monitoring the batch jobs.
  ·	Monitor security batch processing jobs in multi-platform shop via Control-M & Tidal Schedulers.
  
      Project: Enterprise Tax Management Service
  ·	Involved in Business analysis and requirements gathering. Generating and validating the Cognos reports based on functionality. Extensively tested several Cognos reports for data quality, fonts, headers & cosmetic errors.
  ·	Written several complex SQL queries for validating Cognos Reports with the source and target system (data warehouse) data. Documented Test Summary Report and Validation Summary Report.
  ·	Defined data requirements and elements used in XML transactions. 
  ·	Created and scheduled sessions and workflows using Workflow Manager to load the data into the Target Database.
  ·	Validation of mappings and verification of transformations using Source Qualifier, Update Strategy, Stored Procedure and Expressions according to the business rules and technical specifications.
  ·	Testing of mapping parameters and variables.
  ·	Performed Gap Analysis, Risk assessment and gave remediation plan to get the systems into compliance. Responsible for testing and validating target data, fixing invalid mappings.
  ·	Used workflow manager for session management, database connection management and scheduling of jobs. Written several shell scripts using UNIX Korn shell for file transfers, error log creations and log file cleanup process.
  </p>

<p>Education

  Master’s from Mississippi College, Mississippi, USA.             08/20/2009-05/20/2011
  Graduated in 2011
  
     Bachelors, Osmania University, India                                     08/01/2005-05/30/2009
     Graduated in 2009
  
  
  Licenses & Certifications
  
   Infrastructure and Application Modernization with Google Cloud – Coursera
   Credential ID NV92ETWWT8U3
  
   Google Cloud Fundamentals: Core Infrastructure – Coursera
   Credential ID NTXEE2JTF2X8
  
   Getting Started with Google Kubernetes Engine – Coursera
   Credential ID 59YW4E8Y5PEK
  
  
  #ncr-unconference-and-global-hackathon in NCR-SaaS
  Participated in many Innovation jams where I was leading in developing an idea and a prototype for patented NCR technology.  Won 1st prize in one of the innovation jam ideas that I have come up with and worked on. 
  
  My Hackathons/Innovation Jam Submissions at NCR:
  Developed prototypes on both online and mobile banking within 72 hours for the ideas that I presented during our annual and semi-annual hackathons:
  
  Troubleshooting Tool (In 2016 Spring): Created a tool that acts like the end-user and replicates the error that user is facing at the FI (Financial Institution). This helped us eliminate the need to ask for screen captures and logs from end-user. We assumed writing to splunk logs and march towards resolving the issue. 
  
  My Favorites! “Intelligent Banking” (In 2016 Summer: We own the 1st prize for this will patent pending): This increased the revenue for NCR. Back-end solution that can hook into one or all front-end solutions. Omni-channel (OLB, Mobile, SMS). Identify customer's spending behavior would lead to potential for cross-sell. 
  
  Multi-currency UI display (In 2017 Summer): Currency Calculated UI. ‘Currency Converter’ tab on the Online Banking (OLB)/Mobile screen converts the currency based on the live exchange rates. Currency converted is applied to all accounts on the Account Home page included the Amount Dues, BillPay, etc. International wire transfers also show the converted currency to display the exact amount that needs to be transferred.
  
  Blockchain and AI idea (In 2018 Summer)
  
  iSafe: Mobile SAFE Access (In 2019 Summer): As personal banking goes digital, why not safe deposit box? While at the bank we open our mobile bank app and look for the feature ’mobile safe access' and request a code which we enter on the safe deposit box. The bank associate also has a code or they can still go the traditional way of using a key from their end. This feature - Mobile Safe Access can generate a pin that expires every 5 minutes. More secure.
  </p>